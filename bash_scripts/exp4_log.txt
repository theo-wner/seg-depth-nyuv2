Seed set to 42
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name                  | Type                       | Params
---------------------------------------------------------------------
0 | model                 | SegformerForSegDepth       | 50.4 M
1 | seg_loss              | CrossEntropyLoss           | 0     
2 | depth_loss            | RMSLELoss                  | 0     
3 | seg_iou               | MulticlassJaccardIndex     | 0     
4 | seg_calibration_error | MulticlassCalibrationError | 0     
---------------------------------------------------------------------
50.4 M    Trainable params
0         Non-trainable params
50.4 M    Total params
201.617   Total estimated model params size (MB)
`Trainer.fit` stopped: `max_epochs=400` reached.
-------------------------------------------------------------------------
Seed set to 42
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name                  | Type                       | Params
---------------------------------------------------------------------
0 | model                 | SegformerForSegDepth       | 50.4 M
1 | seg_loss              | CrossEntropyLoss           | 0     
2 | depth_loss            | RMSLELoss                  | 0     
3 | seg_iou               | MulticlassJaccardIndex     | 0     
4 | seg_calibration_error | MulticlassCalibrationError | 0     
---------------------------------------------------------------------
50.4 M    Trainable params
0         Non-trainable params
50.4 M    Total params
201.617   Total estimated model params size (MB)
`Trainer.fit` stopped: `max_epochs=400` reached.
-------------------------------------------------------------------------
Seed set to 42
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name                  | Type                       | Params
---------------------------------------------------------------------
0 | model                 | SegformerForSegDepth       | 50.4 M
1 | seg_loss              | CrossEntropyLoss           | 0     
2 | depth_loss            | RMSLELoss                  | 0     
3 | seg_iou               | MulticlassJaccardIndex     | 0     
4 | seg_calibration_error | MulticlassCalibrationError | 0     
---------------------------------------------------------------------
50.4 M    Trainable params
0         Non-trainable params
50.4 M    Total params
201.617   Total estimated model params size (MB)
`Trainer.fit` stopped: `max_epochs=400` reached.
-------------------------------------------------------------------------
Seed set to 42
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name                  | Type                       | Params
---------------------------------------------------------------------
0 | model                 | SegformerForSegDepth       | 50.4 M
1 | seg_loss              | CrossEntropyLoss           | 0     
2 | depth_loss            | RMSLELoss                  | 0     
3 | seg_iou               | MulticlassJaccardIndex     | 0     
4 | seg_calibration_error | MulticlassCalibrationError | 0     
---------------------------------------------------------------------
50.4 M    Trainable params
0         Non-trainable params
50.4 M    Total params
201.617   Total estimated model params size (MB)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
`Trainer.fit` stopped: `max_epochs=400` reached.
-------------------------------------------------------------------------
Seed set to 42
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name                  | Type                       | Params
---------------------------------------------------------------------
0 | model                 | SegformerForSegDepth       | 50.4 M
1 | seg_loss              | CrossEntropyLoss           | 0     
2 | depth_loss            | RMSLELoss                  | 0     
3 | seg_iou               | MulticlassJaccardIndex     | 0     
4 | seg_calibration_error | MulticlassCalibrationError | 0     
---------------------------------------------------------------------
50.4 M    Trainable params
0         Non-trainable params
50.4 M    Total params
201.617   Total estimated model params size (MB)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
`Trainer.fit` stopped: `max_epochs=400` reached.
-------------------------------------------------------------------------
Seed set to 42
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name                  | Type                       | Params
---------------------------------------------------------------------
0 | model                 | SegformerForSegDepth       | 50.4 M
1 | seg_loss              | CrossEntropyLoss           | 0     
2 | depth_loss            | RMSLELoss                  | 0     
3 | seg_iou               | MulticlassJaccardIndex     | 0     
4 | seg_calibration_error | MulticlassCalibrationError | 0     
---------------------------------------------------------------------
50.4 M    Trainable params
0         Non-trainable params
50.4 M    Total params
201.617   Total estimated model params size (MB)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
`Trainer.fit` stopped: `max_epochs=400` reached.
-------------------------------------------------------------------------
